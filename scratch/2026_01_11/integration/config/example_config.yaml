# scRNA-seq Integration Configuration
# =====================================
#
# This config file controls the integration workflow.
# Copy and modify for your specific analysis.

# Input data
input:
  # For merge step: list of h5ad files to merge
  files:
    - path: "/path/to/dataset1.h5ad"
      name: "sc_islet"
    - path: "/path/to/dataset2.h5ad"
      name: "primary_islet"

  # For integration step: path to merged h5ad
  h5ad_path: "./results/merged.h5ad"

  # Column name for batch after merge
  batch_key: "dataset"

# Preprocessing parameters
preprocessing:
  n_top_genes: 3000          # Number of highly variable genes
  regress_out: null          # Variables to regress out, e.g., ["total_counts", "pct_counts_mt"]
  max_scale_value: 10        # Max value after scaling
  n_pcs: 50                  # Number of principal components

# Integration parameters
integration:
  # Key to use for batch correction (can differ from batch_key)
  # e.g., use "sample_id" for sample-level correction
  # or "donor_id" for donor-level correction
  key: "sample_id"

  # Additional variables to plot in method comparison figures
  # The integration key is always plotted; these are extras
  # Will be skipped if not present in the data
  plot_vars:
    - "cell_type"            # Cell type annotations
    # - "donor_id"           # Donor/patient ID
    # - "condition"          # Experimental condition

  # Harmony-specific settings (R/rpy2)
  harmony:
    theta: null              # Diversity clustering penalty (null = default)

  # Seurat-specific settings (R/rpy2)
  seurat:
    methods:                 # Methods to compare
      - "cca"                # Canonical Correlation Analysis
      - "rpca"               # Reciprocal PCA
      - "harmony"            # Harmony via Seurat
      - "fastmnn"            # Fast Mutual Nearest Neighbors

  # scVI-specific settings (Python)
  scvi:
    n_latent: 30             # Latent space dimensions
    n_layers: 2              # Encoder/decoder layers
    n_epochs: 400            # Max training epochs (null = auto)
    early_stopping: true     # Use early stopping

  # Scanorama-specific settings (Python)
  scanorama:
    knn: 20                  # K-nearest neighbors for matching

# Clustering parameters
clustering:
  resolutions:               # Leiden resolutions to test
    - 0.2
    - 0.5
    - 0.8
    - 1.0
  n_neighbors: 30            # Neighbors for graph construction

# Downsampling configuration (optional, for merge step)
# The full merged dataset is ALWAYS saved as merged.h5ad
# Downsampled versions are saved as additional files with descriptive names
downsampling:
  seed: 42                   # Random seed for reproducibility

  # Random downsampling - simple random sampling to target cell counts
  # Supports single value (50000) or list ([10000, 25000, 50000])
  # Each value creates: merged_random_{n}.h5ad
  random:
    n_cells: []              # e.g., [10000, 25000, 50000] or 50000

  # Cell type aware downsampling - match cell types across datasets
  # Keeps only shared cell types (unless keep_unshared: true)
  # Each value creates: merged_celltype_{n}pertype.h5ad
  celltype_aware:
    celltype_column: "cell_type"  # Column containing cell type annotations
    n_cells_per_type: []          # e.g., [500, 1000] or 1000
    keep_unshared: false          # If true, keep cell types not in all datasets
    min_cells_per_type: 10        # Min cells required to keep a cell type

# Output settings
output:
  dir: "./results/"          # Output directory
  save_slim: true            # Save minimal h5ad (counts, obs, obsm only)
  save_markers: true         # Compute and save marker genes
  save_model: true           # Save scVI model for transfer learning

# ==================================
# Example Usage
# ==================================
#
# 1. Merge datasets (full + optional downsampled versions):
#    python scripts/merge_datasets.py --config config/example_config.yaml
#
#    # Or with CLI overrides for downsampling:
#    python scripts/merge_datasets.py --config config/example_config.yaml \
#        --downsample-random 10000 25000 50000 \
#        --downsample-celltype 500 1000
#
# 2. Run Harmony integration:
#    python scripts/harmony_integration.py --config config/example_config.yaml
#
# 3. Run Seurat integration (Python wrapper):
#    python scripts/seurat_integration.py --config config/example_config.yaml
#
# 4. Run Seurat integration (pure R, for HPC/SLURM):
#    Rscript scripts/seurat_integration.R --config config/example_config.yaml
#    # Or via SLURM:
#    sbatch scripts/submit_seurat_integration.sh --config config/example_config.yaml
#
# 5. Run Python integration (scVI/Scanorama):
#    python scripts/python_integration.py --config config/example_config.yaml
#
# Or use the notebooks interactively:
#    - notebooks/01_merge_datasets.ipynb
#    - notebooks/02_harmony_integration.ipynb
#    - notebooks/03_seurat_integration.ipynb
#    - notebooks/04_python_integration.ipynb
#    - notebooks/04_seurat_integrationR.ipynb (pure R)
